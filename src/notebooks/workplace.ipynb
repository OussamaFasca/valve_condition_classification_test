{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import f1_score,accuracy_score,precision_score,recall_score,confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import warnings\n",
    "import joblib\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module='_distutils_hack')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data From CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load your data\n",
    "fs1 = pd.read_csv('../data/raw/FS1.txt', delimiter='\\t', header=None)\n",
    "ps2 = pd.read_csv('../data/raw/PS2.txt', delimiter='\\t', header=None)\n",
    "\n",
    "profile_column_names = [\n",
    "    'Cooler condition (%)',\n",
    "    'Valve condition (%)',\n",
    "    'Internal pump leakage',\n",
    "    'Hydraulic accumulator (bar)',\n",
    "    'Stable flag'\n",
    "]\n",
    "\n",
    "profile = pd.read_csv('../data/raw/profile.txt', delimiter='\\t', header=None, names=profile_column_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Formatting target data as True/False (1/0) signifying optimal valve condition (100% being 1/True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "profile[\"Valve condition Status\"] = profile[\"Valve condition (%)\"].apply(lambda x: 1 if x == 100 else 0)\n",
    "profile = profile[[\"Valve condition Status\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of using every captured measure in the 60 seconds cycle, and to reduce the dimensionality of the input Data, I created a function to calculate the mean of multiple measures in a specific timeframe (**In my case, i am using the mean of measures in 10seconds timeframes**).\n",
    "* FS1 : the FS1 measures are done on 10hz frequency, meaning 10 measures per second. **in my code, i take the mean of 100 measures in a 10 seconds timeframe, presenting my with only 6 features as input**\n",
    "\n",
    "* PS2 : the PS2 measures are done on 100hz frequency, meaning 100 measures per second**in my code, i take the mean of 1000 measures in a 10 seconds timeframe, presenting my with only 6 features as input**\n",
    "\n",
    "I end up with 12 features coming from FS1 and PS2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def features_mean_measures_preparation(df, group_size, dataset_prefix):\n",
    "    df = df.T\n",
    "    df[f\"cycle\"] = (df.index // group_size)\n",
    "    df = df.groupby('cycle').mean().T\n",
    "    df.columns = [f\"{dataset_prefix}_mean_measure_at_{i + 1}0th_second\" for i in range(len(df.columns))]\n",
    "    return df\n",
    "\n",
    "engineered_fs1 = features_mean_measures_preparation(fs1, 100, \"fs1\")\n",
    "engineered_ps2 = features_mean_measures_preparation(ps2, 1000, \"ps2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concatenate data based on index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.concat([engineered_fs1, engineered_ps2, profile], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fs1_mean_measure_at_10th_second': {0: 0.98779, 1: 0.9428300000000001},\n",
       " 'fs1_mean_measure_at_20th_second': {0: 7.83661, 1: 7.84971},\n",
       " 'fs1_mean_measure_at_30th_second': {0: 7.6888499999999995, 1: 7.70148},\n",
       " 'fs1_mean_measure_at_40th_second': {0: 7.93828, 1: 7.96244},\n",
       " 'fs1_mean_measure_at_50th_second': {0: 7.937, 1: 7.9485},\n",
       " 'fs1_mean_measure_at_60th_second': {0: 7.87036, 1: 7.8869299999999996},\n",
       " 'ps2_mean_measure_at_10th_second': {0: 9.512161, 1: 9.566111999999999},\n",
       " 'ps2_mean_measure_at_20th_second': {0: 121.12585, 1: 121.08698},\n",
       " 'ps2_mean_measure_at_30th_second': {0: 131.31226, 1: 131.12716},\n",
       " 'ps2_mean_measure_at_40th_second': {0: 139.6496, 1: 139.48404000000002},\n",
       " 'ps2_mean_measure_at_50th_second': {0: 129.96391, 1: 129.83252000000002},\n",
       " 'ps2_mean_measure_at_60th_second': {0: 125.2377, 1: 125.03253},\n",
       " 'Valve condition Status': {0: 1, 1: 1}}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df.head(2).to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Storing dataset as feather file for serving the model\n",
    "-- to predict output based on index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.to_feather('../data/merged_dataset/dataset.feather')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Splitting\n",
    "Using only the first 2000 rows for training and testing the model, while preserving remaining data for final evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "remaining_data = merged_df.iloc[2000:]\n",
    "merged_df = merged_df.iloc[:2000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into features (X) and target (y)\n",
    "X = merged_df.drop(columns=['Valve condition Status'])\n",
    "y = merged_df['Valve condition Status']\n",
    "\n",
    "# Data splitting into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Scaling and saving scaler for model serving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../saved_models/scaler.pkl']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "joblib.dump(scaler, '../saved_models/scaler.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining evaluation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to calculate metrics and return them as a dictionary\n",
    "def calculate_metrics(y_true, y_pred):\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred)\n",
    "    recall = recall_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    return {'Accuracy': accuracy, 'Precision': precision, 'Recall': recall, 'F1 Score': f1, 'Confusion Matrix': cm}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training, Testing, and evaluating results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Confusion Matrix</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[[197, 0], [0, 203]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.9950</td>\n",
       "      <td>0.995074</td>\n",
       "      <td>0.995074</td>\n",
       "      <td>0.995074</td>\n",
       "      <td>[[196, 1], [1, 202]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Gaussian Naive Bayes</td>\n",
       "      <td>0.8675</td>\n",
       "      <td>0.820513</td>\n",
       "      <td>0.945813</td>\n",
       "      <td>0.878719</td>\n",
       "      <td>[[155, 42], [11, 192]]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Model  Accuracy  Precision    Recall  F1 Score  \\\n",
       "0   Logistic Regression    1.0000   1.000000  1.000000  1.000000   \n",
       "1         Random Forest    0.9950   0.995074  0.995074  0.995074   \n",
       "2  Gaussian Naive Bayes    0.8675   0.820513  0.945813  0.878719   \n",
       "\n",
       "         Confusion Matrix  \n",
       "0    [[197, 0], [0, 203]]  \n",
       "1    [[196, 1], [1, 202]]  \n",
       "2  [[155, 42], [11, 192]]  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize models\n",
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(max_iter=1000),\n",
    "    'Random Forest': RandomForestClassifier(),\n",
    "    'Gaussian Naive Bayes': GaussianNB()\n",
    "}\n",
    "\n",
    "# Train and evaluate each model\n",
    "results = []\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    \n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "    # Calculate metrics\n",
    "    metrics = calculate_metrics(y_test, y_pred)\n",
    "    # Append results\n",
    "    results.append({'Model': model_name, **metrics})\n",
    "\n",
    "# Convert results to DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross validation for better evaluation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cross-validation results (mean scores):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Mean F1 Score</th>\n",
       "      <th>Mean Accuracy</th>\n",
       "      <th>Mean Precision</th>\n",
       "      <th>Mean Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.999522</td>\n",
       "      <td>0.9995</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.959698</td>\n",
       "      <td>0.9660</td>\n",
       "      <td>0.997187</td>\n",
       "      <td>0.940952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Gaussian Naive Bayes</td>\n",
       "      <td>0.885988</td>\n",
       "      <td>0.8760</td>\n",
       "      <td>0.866103</td>\n",
       "      <td>0.936190</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Model  Mean F1 Score  Mean Accuracy  Mean Precision  \\\n",
       "0   Logistic Regression       0.999522         0.9995        1.000000   \n",
       "1         Random Forest       0.959698         0.9660        0.997187   \n",
       "2  Gaussian Naive Bayes       0.885988         0.8760        0.866103   \n",
       "\n",
       "   Mean Recall  \n",
       "0     0.999048  \n",
       "1     0.940952  \n",
       "2     0.936190  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Optional: Cross-validation for more robust evaluation\n",
    "cv_results = []\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    \n",
    "    # Calculate metrics for cross-validation\n",
    "    cv_metrics = {\n",
    "        'Mean F1 Score': cross_val_score(model, X, y, cv=10, scoring='f1').mean(),\n",
    "        'Mean Accuracy': cross_val_score(model, X, y, cv=10, scoring='accuracy').mean(),\n",
    "        'Mean Precision': cross_val_score(model, X, y, cv=10, scoring='precision').mean(),\n",
    "        'Mean Recall': cross_val_score(model, X, y, cv=10, scoring='recall').mean()\n",
    "    }\n",
    "    \n",
    "    # Append cross-validation results\n",
    "    cv_results.append({'Model': model_name, **cv_metrics})\n",
    "\n",
    "# Convert cross-validation results to DataFrame\n",
    "cv_results_df = pd.DataFrame(cv_results)\n",
    "\n",
    "# Print cross-validation results\n",
    "print(\"\\nCross-validation results (mean scores):\")\n",
    "cv_results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the remaining data for final evaluation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results using remaining data (beyond first 2000 rows):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Confusion Matrix</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[[132, 0], [0, 73]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.975610</td>\n",
       "      <td>0.935897</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.966887</td>\n",
       "      <td>[[127, 5], [0, 73]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Gaussian Naive Bayes</td>\n",
       "      <td>0.756098</td>\n",
       "      <td>0.593496</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.744898</td>\n",
       "      <td>[[82, 50], [0, 73]]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Model  Accuracy  Precision  Recall  F1 Score  \\\n",
       "0   Logistic Regression  1.000000   1.000000     1.0  1.000000   \n",
       "1         Random Forest  0.975610   0.935897     1.0  0.966887   \n",
       "2  Gaussian Naive Bayes  0.756098   0.593496     1.0  0.744898   \n",
       "\n",
       "      Confusion Matrix  \n",
       "0  [[132, 0], [0, 73]]  \n",
       "1  [[127, 5], [0, 73]]  \n",
       "2  [[82, 50], [0, 73]]  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Separate features (X_remaining) and target (y_remaining)\n",
    "X_remaining = remaining_data.drop(columns=['Valve condition Status'])\n",
    "y_remaining = remaining_data['Valve condition Status']\n",
    "\n",
    "# Scale the remaining data using the previously fitted scaler\n",
    "X_remaining_scaled = scaler.transform(X_remaining)\n",
    "\n",
    "# Initialize an empty list to store results for remaining data\n",
    "remaining_results = []\n",
    "\n",
    "# Evaluate each model on remaining data\n",
    "for model_name, model in models.items():\n",
    "    # Predict using the model on scaled remaining data\n",
    "    y_pred_remaining = model.predict(X_remaining_scaled)\n",
    "    \n",
    "    # Calculate metrics for remaining data\n",
    "    metrics_remaining = calculate_metrics(y_remaining, y_pred_remaining)\n",
    "    \n",
    "    # Append results\n",
    "    remaining_results.append({'Model': model_name, **metrics_remaining})\n",
    "\n",
    "# Convert remaining results to DataFrame\n",
    "remaining_results_df = pd.DataFrame(remaining_results)\n",
    "\n",
    "# Print results using remaining data\n",
    "print(\"Results using remaining data (beyond first 2000 rows):\")\n",
    "remaining_results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving model for serving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../saved_models/lr_classifier.pkl']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(models[\"Random Forest\"], '../saved_models/rf_classifier.pkl')\n",
    "joblib.dump(models[\"Logistic Regression\"], '../saved_models/lr_classifier.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
